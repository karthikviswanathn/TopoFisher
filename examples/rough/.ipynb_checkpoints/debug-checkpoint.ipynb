{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2ebecc-eb13-415c-b958-870f53754955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 18:49:16.155205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 18:49:22.492830: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "from copy import deepcopy\n",
    "from gudhi.representations import Landscape, PersistenceImage\n",
    "\n",
    "from topofisher.input_simulators.noisy_ring import CircleSimulator\n",
    "\n",
    "from topofisher.filtrations.numpy.alphaDTML import AlphaDTMLayer\n",
    "\n",
    "from topofisher.vectorizations.numpy.custom_vectorizations import TOPK\n",
    "from topofisher.vectorizations.numpy.vectorization_layer import VectorizationLayers\n",
    "from topofisher.vectorizations.numpy.shorthand_layers import PersistenceImages, PersistenceLandscapes\n",
    "\n",
    "from topofisher.fisher.Fisher import show_fm_and_bias\n",
    "from topofisher.fisher.imnn import IMNNLayer, MopedLayer, ExtraDimLayer\n",
    "from topofisher.fisher.plot_fisher_stats import plotContours2D, plotSummaryDerivativeHists, plot_derivative_convergence\n",
    "\n",
    "\n",
    "from topofisher.pipelines.circle import CirclePipeline\n",
    "from topofisher.pipelines.convergence_checks import fisher_estimates_wrt_step_size\n",
    "from topofisher.pipelines.utils import readFromFile, writeToFile\n",
    "\n",
    "import gudhi.representations as gdr\n",
    "import gudhi.tensorflow.perslay as prsl\n",
    "from gudhi.point_cloud.knn import KNearestNeighbors\n",
    "from topofisher.input_simulators.noisy_ring import CircleSimulator\n",
    "import gudhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0897d9e9-820d-4fdd-94b9-c4556f48ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixDTMAndL:\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        self.name = \"Mix DTML\"\n",
    "    \n",
    "    def ef_tf(self, pts, vf, inds):\n",
    "        p = self.p\n",
    "        fmax = tf.math.maximum(tf.gather(vf, inds[:,0]), \\\n",
    "                               tf.gather(vf, inds[:,1]))\n",
    "         \n",
    "        edge_coords = tf.gather(pts, inds)\n",
    "        start, end = edge_coords[:, 0, :], edge_coords[:, 1, :] \n",
    "        d = tf.linalg.norm(start - end, axis = -1)\n",
    "        return (d**p + fmax**p)**(1/p)\n",
    "    \n",
    "    # TODO : Note that the input signatures are different with the \"tf\" version.\n",
    "    def ef_np(self, pts, filt, inds):\n",
    "        p = self.p\n",
    "        pc = p.numpy() if(tf.is_tensor(p)) else p \n",
    "        inda, indb = inds[:,0], inds[:,1]    \n",
    "        d = np.linalg.norm(pts[inda] - pts[indb], axis = -1)\n",
    "        fx, fy = filt[inda], filt[indb] \n",
    "        fmax = np.maximum(fx, fy)\n",
    "        return (d**pc+fmax**pc)**(1/pc)\n",
    "\n",
    "class DTMFiltLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_hom_dim, complex_args, num_nn, efilt, perslays, autodiff = True, tqdm = False, **kwargs):\n",
    "        tf.keras.layers.Layer.__init__(self, **kwargs)\n",
    "        self.max_hom_dim = max_hom_dim\n",
    "        self.complex_args = complex_args\n",
    "        self.num_nn = num_nn\n",
    "        self.autodiff = autodiff\n",
    "        self.tqdm = tqdm\n",
    "        self.efilt = efilt\n",
    "        self.perslays = perslays\n",
    "        \n",
    "    def find_knn_matrices(self, inputs):\n",
    "        all_dists = [] \n",
    "        for pc in inputs:\n",
    "            knn = KNearestNeighbors(self.num_nn, return_index = False, return_distance = True, \\\n",
    "                                    enable_autodiff = self.autodiff)\n",
    "            dists = knn.fit_transform(pc)\n",
    "            all_dists.append(pc)\n",
    "        return tf.stack(all_dists)\n",
    "        \n",
    "    def vFilt(self, knn_matrices):\n",
    "        return tf.math.sqrt(tf.math.reduce_mean(knn_matrices ** 2, axis = -1))\n",
    "\n",
    "    def computePP(self, allPts, allFilts):\n",
    "        pp = []        \n",
    "        iter_obs = tqdm(zip(allPts, allFilts), total = len(allPts)) if self.tqdm \\\n",
    "            else zip(allPts, allFilts)\n",
    "        for pts, vfilt in iter_obs:\n",
    "            st = self.createSimplexTree(pts, vfilt)\n",
    "            pp.append(st.flag_persistence_generators())     \n",
    "        return pp\n",
    "    \n",
    "    def createSimplexTree(self, pts, vfilt):\n",
    "        st =  self.getSimplexTree(pts)\n",
    "        vert = np.array([s[0] for s in st.get_skeleton(0)])\n",
    "        edges = np.array([s[0] for s in st.get_skeleton(1)\\\n",
    "                          if len(s[0]) == 2])\n",
    "        \n",
    "        efilt = self.efilt.ef_np(pts, vfilt, edges)\n",
    "        st = gudhi.SimplexTree()\n",
    "        st.insert_batch(vert.T, vfilt.reshape(-1))\n",
    "        st.insert_batch(edges.T, efilt)\n",
    "        st.expansion(self.max_hom_dim)\n",
    "        st.make_filtration_non_decreasing()\n",
    "        st.persistence()\n",
    "        return st;\n",
    "    \n",
    "    def getSimplexTree(self, pts, default = False):\n",
    "        complex_args = self.complex_args\n",
    "        complex_type = complex_args['complex_type']\n",
    "        \n",
    "        if(complex_type  == \"alpha\") :\n",
    "            alpha = gudhi.AlphaComplex(points = pts)\n",
    "            st = alpha.create_simplex_tree(default_filtration_value = not default)\n",
    "            \n",
    "        if(complex_type  == \"rips\") :\n",
    "            max_edge = complex_args['max_edge'] if 'max_edge' in complex_args.keys() \\\n",
    "                                                else np.inf\n",
    "            sparse = complex_args['sparse'] if 'sparse' in complex_args.keys() \\\n",
    "                                            else None\n",
    "            rips = gudhi.RipsComplex(points = pts, max_edge_length = max_edge, \\\n",
    "                                     sparse = sparse)\n",
    "            st = rips.create_simplex_tree(max_dimension = 2)\n",
    "        \n",
    "        return st\n",
    "\n",
    "    def getPDFromPairs(self, pts, pers_pairs, vFilts):                     \n",
    "        efilt = self.efilt\n",
    "        pd0, pd1 = [], []\n",
    "        vecs = []\n",
    "        for pt, pers, vf  in zip(pts, pers_pairs, vFilts) :\n",
    "            ind0, ind1 = pers[0], pers[1][0]\n",
    "            # print(len(ind0), len(ind1))\n",
    "            # print(len(pers[1][0]))\n",
    "            b0 = tf.gather(vf, ind0[:,0])\n",
    "            pt, vf = pt.numpy(), vf.numpy()\n",
    "            d0 = efilt.ef_np(pt, vf, ind0[:, 1:])\n",
    "            b1 = efilt.ef_np(pt, vf, ind1[:, :2])\n",
    "            d1 = efilt.ef_np(pt, vf, ind1[:, 2:])\n",
    "            \"\"\"\n",
    "            d0 = tf.gather_nd(dx, ind0[:, 1:]) \n",
    "            b1 = tf.gather_nd(dx, ind1[:, :2])\n",
    "            d1 = tf.gather_nd(dx, ind1[:, 2:])\n",
    "            \"\"\"\n",
    "            diag0, diag1 = tf.stack([b0, d0], axis = -1), tf.stack([b1, d1], axis = -1)\n",
    "            pd0.append(diag0)\n",
    "            pd1.append(diag1)\n",
    "            play0, play1 = self.perslays\n",
    "            vec0  = play0(tf.expand_dims(diag0, 0))[0]\n",
    "            vec1  = play1(tf.expand_dims(diag1, 0))[0]\n",
    "            vecs.append(tf.concat([vec0, vec1], axis = -1))\n",
    "        return pd0, pd1\n",
    "        # return tf.stack(vecs)\n",
    "    \n",
    "    def stack_ragged(self, tensors):\n",
    "        values = tf.concat(tensors, axis = 0)\n",
    "        lens = tf.stack([tf.shape(t, out_type=tf.int64)[0] for t in tensors])\n",
    "        return tf.RaggedTensor.from_row_lengths(values, lens)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        knn_matrices = self.find_knn_matrices(inputs)\n",
    "        vFilts = self.vFilt(knn_matrices)\n",
    "        pps = self.computePP(inputs.numpy(), vFilts.numpy())\n",
    "        \n",
    "        return self.getPDFromPairs(inputs, pps, vFilts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e9079d-6200-485c-a6cb-d19d10fc393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_pipeline = readFromFile(\"pipeline_m_p9_ns_4K_dtheta_p01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cab6f54-9577-4591-bc93-07b8b65a2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 10\n",
    "theta_fid = tf.constant([1., 0.2])\n",
    "noisy_ring =  CircleSimulator(200, 20, 1.)\n",
    "all_pts = noisy_ring.generateInstances(theta_fid, num_sims, seed = circle_pipeline.seed_cov)\n",
    "filtLayer_new = DTMFiltLayer(max_hom_dim = 2, efilt = MixDTMAndL(p = 1), perslays = [[],[]], \\\n",
    "                             complex_args = {'complex_type':\"alpha\"}, num_nn = 198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6809525d-fe88-49d1-87dc-37dfa7869ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtLayer = AlphaDTMLayer(m = 0.9, max_hom_dim = 2, hom_dim_list = [0, 1], show_tqdm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ce27c-2d3a-4279-8b6b-b57b1263c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = filtLayer.get_st(all_pts[ind].numpy())\n",
    "fpg = st.flag_persistence_generators()\n",
    "fpg[0] - filtLayer_new(all_pts)[ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4349116d-03c4-4ff3-ad61-97e6161c3a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 0\n",
    "len(filtLayer_new(all_pts)[ind][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "149af56a-fd0a-479d-8c49-d3b1a9814c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = filtLayer_new(all_pts)[ind][0];\n",
    "B = fpg[0]\n",
    "for item in B:\n",
    "    if item not in A:\n",
    "        print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4297c-efb4-41be-9c76-12a98eae8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "setA - setB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487e0b4-6563-4c72-9b4c-dcbadeb3720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = filtLayer_new(all_pts)[ind][0];\n",
    "B = fpg[0]\n",
    "setA = {tuple(row) for row in A}\n",
    "setB = {tuple(row) for row in B}\n",
    "setA - setB, setB - setA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efbbd7cb-24a4-4f37-9e0f-ce3b80576fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = filtLayer_new(all_pts)[ind][1][0];\n",
    "B = fpg[1][0]\n",
    "for item in A:\n",
    "    if item not in B:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a853621d-ec6f-43d0-bdbc-9f0afa4e1461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 54\n"
     ]
    }
   ],
   "source": [
    "for item in B:\n",
    "    if item not in A:\n",
    "        print(item)\n",
    "print(len(A), len(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc3e841-44d0-48fa-91a2-6efd36881e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "hom_dim = 1; ind = 0;\n",
    "pds[hom_dim][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba97e28-18c7-4601-9400-d04e6efc9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = filtLayer.get_st(all_pts[ind].numpy())\n",
    "st.flag_persistence_generators() - filtLayer_new(all_pts)[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb90fe1-0698-43e0-994c-f946d1a6e9f2",
   "metadata": {},
   "source": [
    "### Plotting PD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e75dc7a-a278-49db-b427-891ec18a3bfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"dtm_filt_layer_2\" \"                 f\"(type DTMFiltLayer).\n\n'ListWrapper' object is not callable\n\nCall arguments received by layer \"dtm_filt_layer_2\" \"                 f\"(type DTMFiltLayer):\n  • inputs=tf.Tensor(shape=(10, 220, 2), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pd1 \u001b[38;5;241m=\u001b[39m filtLayer\u001b[38;5;241m.\u001b[39mfind_persistence_diagrams(all_pts)[ind]\n\u001b[0;32m----> 2\u001b[0m pd1p \u001b[38;5;241m=\u001b[39m \u001b[43mfiltLayer_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_pts\u001b[49m\u001b[43m)\u001b[49m[ind][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(pd1[:,\u001b[38;5;241m0\u001b[39m], pd1[:,\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/newEnvbkup/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[17], line 130\u001b[0m, in \u001b[0;36mDTMFiltLayer.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    127\u001b[0m vFilts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvFilt(knn_matrices)\n\u001b[1;32m    128\u001b[0m pps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputePP(inputs\u001b[38;5;241m.\u001b[39mnumpy(), vFilts\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPDFromPairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvFilts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 114\u001b[0m, in \u001b[0;36mDTMFiltLayer.getPDFromPairs\u001b[0;34m(self, pts, pers_pairs, vFilts)\u001b[0m\n\u001b[1;32m    112\u001b[0m pd1\u001b[38;5;241m.\u001b[39mappend(diag1)\n\u001b[1;32m    113\u001b[0m play0, play1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperslays\n\u001b[0;32m--> 114\u001b[0m vec0  \u001b[38;5;241m=\u001b[39m \u001b[43mplay0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiag0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    115\u001b[0m vec1  \u001b[38;5;241m=\u001b[39m play1(tf\u001b[38;5;241m.\u001b[39mexpand_dims(diag1, \u001b[38;5;241m0\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    116\u001b[0m vecs\u001b[38;5;241m.\u001b[39mappend(tf\u001b[38;5;241m.\u001b[39mconcat([vec0, vec1], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"dtm_filt_layer_2\" \"                 f\"(type DTMFiltLayer).\n\n'ListWrapper' object is not callable\n\nCall arguments received by layer \"dtm_filt_layer_2\" \"                 f\"(type DTMFiltLayer):\n  • inputs=tf.Tensor(shape=(10, 220, 2), dtype=float32)"
     ]
    }
   ],
   "source": [
    "pd1 = filtLayer.find_persistence_diagrams(all_pts)[ind]\n",
    "pd1p = filtLayer_new(all_pts)[ind][1][0]\n",
    "plt.scatter(pd1[:,0], pd1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc441b5-5a40-4411-85fd-c608b95d559f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnvbkup",
   "language": "python",
   "name": "newenvbkup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
