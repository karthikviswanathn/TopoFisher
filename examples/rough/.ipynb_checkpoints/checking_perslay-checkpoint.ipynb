{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0783b9e6-5489-4f3b-8c7f-1074d5816e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 19:13:09.284905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-23 19:13:13.374887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "from copy import deepcopy\n",
    "from gudhi.representations import Landscape, PersistenceImage\n",
    "\n",
    "from topofisher.input_simulators.noisy_ring import CircleSimulator\n",
    "\n",
    "from topofisher.filtrations.numpy.alphaDTML import AlphaDTMLayer\n",
    "\n",
    "from topofisher.vectorizations.numpy.custom_vectorizations import TOPK\n",
    "from topofisher.vectorizations.numpy.vectorization_layer import VectorizationLayers\n",
    "from topofisher.vectorizations.numpy.shorthand_layers import PersistenceImages, PersistenceLandscapes\n",
    "\n",
    "from topofisher.fisher.Fisher import show_fm_and_bias\n",
    "from topofisher.fisher.imnn import IMNNLayer, MopedLayer, ExtraDimLayer\n",
    "from topofisher.fisher.plot_fisher_stats import plotContours2D, plotSummaryDerivativeHists, plot_derivative_convergence\n",
    "\n",
    "\n",
    "from topofisher.pipelines.circle import CirclePipeline\n",
    "from topofisher.pipelines.convergence_checks import fisher_estimates_wrt_step_size\n",
    "from topofisher.pipelines.utils import readFromFile, writeToFile\n",
    "\n",
    "import gudhi.representations as gdr\n",
    "import gudhi.tensorflow.perslay as prsl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf774ae-092e-4010-af8d-34ec81c0a981",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "016c7848-2e2c-4c2b-b662-67c528e1d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import topofisher\n",
    "importlib.reload(topofisher.fisher.Fisher)\n",
    "importlib.reload(topofisher.fisher.imnn)\n",
    "\n",
    "importlib.reload(topofisher.filtrations.numpy.filtration_layers)\n",
    "importlib.reload(topofisher.filtrations.numpy.alphaDTML)\n",
    "\n",
    "importlib.reload(topofisher.vectorizations.numpy.vectorization_layer)\n",
    "importlib.reload(topofisher.vectorizations.numpy.shorthand_layers)\n",
    "importlib.reload(topofisher.input_simulators.noisy_ring)\n",
    "importlib.reload(topofisher.pipelines.pipeline)\n",
    "importlib.reload(topofisher.pipelines.circle)\n",
    "\n",
    "from topofisher.input_simulators.noisy_ring import CircleSimulator\n",
    "\n",
    "from topofisher.filtrations.numpy.alphaDTML import AlphaDTMLayer\n",
    "\n",
    "from topofisher.vectorizations.numpy.custom_vectorizations import TOPK\n",
    "from topofisher.vectorizations.numpy.vectorization_layer import VectorizationLayers\n",
    "from topofisher.vectorizations.numpy.shorthand_layers import PersistenceImages, PersistenceLandscapes\n",
    "\n",
    "importlib.reload(topofisher.fisher.imnn)\n",
    "from topofisher.fisher.imnn import IMNNLayer, FisherLayer, MopedLayer, ExtraDimLayer\n",
    "from topofisher.fisher.plot_fisher_stats import plotContours2D, plotSummaryDerivativeHists, plot_derivative_convergence\n",
    "\n",
    "\n",
    "from topofisher.pipelines.circle import CirclePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048cbac-2552-477c-859d-4bf332a933ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Initalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97e9648-cf02-45ed-8b31-a6f8f8761b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_pipeline = readFromFile(\"pipeline_m_p9_ns_4K.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6627f9-b7a8-463f-8083-715811be8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams = [tf.constant(item, dtype=tf.float32) for item in circle_pipeline.all_persistence_diagrams[0][1]]\n",
    "def stack_ragged(tensors):\n",
    "    values = tf.concat(tensors, axis=0)\n",
    "    lens = tf.stack([tf.shape(t, out_type=tf.int64)[0] for t in tensors])\n",
    "    return tf.RaggedTensor.from_row_lengths(values, lens)\n",
    "diagrams = stack_ragged(diagrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b2a5e3a6-bc6b-457a-a104-6bb7f344b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 24\n",
    "extent = [[1.03501081e+00, 3.21200657e+00], [2.38418579e-07, 7.95339227e-01]]\n",
    "rho = tf.identity\n",
    "phi = prsl.GaussianPerslayPhi((res, res), extent, 5e-2)\n",
    "weight = prsl.PowerPerslayWeight(1. , 2.)\n",
    "perm_op = tf.math.reduce_sum\n",
    "perslay = prsl.Perslay(phi=phi, weight=weight, perm_op=perm_op, rho=rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d67853-151e-4d4d-a215-8611219bc6e1",
   "metadata": {},
   "source": [
    "### Checking out landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "af504236-f1fe-4331-b7cc-c8bc8aa1602d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gudhi.tensorflow.perslay' from '/Users/karthikviswanathan/opt/anaconda3/envs/newEnvbkup/lib/python3.8/site-packages/gudhi/tensorflow/perslay.py'>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "importlib.reload(prsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "66fbe160-93a9-4ca0-9a8b-ce61d774e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape_layer = PersistenceLandscapes(num_landscapes = [50, 20], resolutions = [30, 30])\n",
    "all_landscapes = []\n",
    "for pds in circle_pipeline.all_persistence_diagrams:\n",
    "    vecs = landscape_layer.vectorize_persistence_diagrams(pds)\n",
    "    all_landscapes.append(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "cef47e5b-1bcc-4af0-a79c-52a84acd87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = prsl.PowerPerslayWeight(1. , 0)\n",
    "\n",
    "phis = [prsl.TentPerslayPhi(item.grid_) for item in landscape_layer.vectorizations]\n",
    "\n",
    "perslays = [prsl.Perslay(phi=phis[0], weight=weight, perm_op='top50', rho=rho),\\\n",
    "            prsl.Perslay(phi=phis[1], weight=weight, perm_op='top20', rho=rho)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "aef376da-95a3-439b-aec8-b3c8a919f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = list_to_ragged_tensor(all_dgms, 5, 2)\n",
    "model = tf.keras.Sequential(\n",
    "    [   ExtraDimLayer(PerslayLayer(perslays)),\n",
    "        tf.keras.layers.Dense(12, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(2)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe9803-e607-4b94-b157-8e8486ce02db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94135d6c-c85c-4638-95c3-a2a041436ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perslay_vec_layer = IMNNLayer(model, verbose = 1, epochs = 20, data_splits = [0.4, 0.2, 0.4], \\\n",
    "                            callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3)], transpose = False)\n",
    "perslay_vec_layer.computeFisher(t2, circle_pipeline.delta_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0ed39-3383-4c9a-919a-71cba786f21a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cheking if perslay matches the PI from gudhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b6b71a2f-e4b5-437f-8ce3-ac97956e9b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.35 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 vectors = perslay(diagrams[:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279249ea-b9c8-40d4-820b-4fb8765d1df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d4a86e-5fad-400a-80f2-7f10b7b07f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4796157 0.11540476\n",
      "5.479616301749681 0.1154047302944399\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectors = perslay(diagrams[:10])\n",
    "\n",
    "res = 24\n",
    "pi_vec_layer = PersistenceImages(resolutions = [[res, res], [res, res]], bandwidths = [3e-2, 5e-2])\n",
    "all_vecs = []\n",
    "for pds in circle_pipeline.all_persistence_diagrams[:][:][:10]:\n",
    "    vecs = pi_vec_layer.vectorize_persistence_diagrams(pds)\n",
    "    all_vecs.append(vecs)\n",
    "all_vecs = tf.stack(all_vecs)\n",
    "\n",
    "ind = 7\n",
    "\n",
    "print(np.max(vectors[ind,:,:,0].numpy()), np.mean(vectors[ind,:,:,0].numpy()))\n",
    "print(np.max(all_vecs[0, ind, :, :, 1]), np.mean(all_vecs[0, ind, :, :, 1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.flip(vectors[ind,:,:,0] - all_vecs[0, ind, :, :, 1].numpy(),0))\n",
    "cb = plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba807da-b2d8-4f41-b08c-36dc2a5d4df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Learning a good vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b54a0c6f-de64-4cec-a059-a9d4411712fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_ragged(tensors):\n",
    "    values = tf.concat(tensors, axis = 0)\n",
    "    lens = tf.stack([tf.shape(t, out_type=tf.int64)[0] for t in tensors])\n",
    "    return tf.RaggedTensor.from_row_lengths(values, lens)\n",
    "\n",
    "class PerslayLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, perslays, **kwargs):\n",
    "        super(PerslayLayer, self).__init__(**kwargs)\n",
    "        self.perslays = perslays\n",
    "    def call(self, inputs):\n",
    "        lis = []\n",
    "        for idx, perslay in enumerate(self.perslays):\n",
    "            diagrams = inputs[:, idx]\n",
    "            # print(diagrams.shape)\n",
    "            lis.append(perslay(diagrams))\n",
    "        return tf.concat(lis, axis = -1)\n",
    "res = 24\n",
    "extents = [item.im_range_fixed_.reshape((2,2)) for item in pi_vec_layer.vectorizations]\n",
    "rho = tf.identity\n",
    "phis = [prsl.GaussianPerslayPhi((res, res), extents[0], 3e-2), prsl.GaussianPerslayPhi((res, res), extents[1], 5e-2)]\n",
    "weights = [prsl.PowerPerslayWeight(1.,2.), prsl.PowerPerslayWeight(1.,2.)]\n",
    "perm_op = tf.math.reduce_sum\n",
    "perslays = [prsl.Perslay(phi=phis[0], weight=weights[0], perm_op=perm_op, rho=rho),\\\n",
    "            prsl.Perslay(phi=phis[1], weight=weights[1], perm_op=perm_op, rho=rho)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0a3da2d-3284-4885-925c-6c6090f9fabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([219 219 219 219 219 219 219 219 219 219], shape=(10,), dtype=int64)\n",
      "tf.Tensor([58 59 45 50 53 47 42 47 42 43], shape=(10,), dtype=int64)\n",
      "tf.Tensor([219 219 219 219 219 219 219 219 219 219], shape=(10,), dtype=int64)\n",
      "tf.Tensor([49 48 46 52 39 47 48 55 53 49], shape=(10,), dtype=int64)\n",
      "tf.Tensor([219 219 219 219 219 219 219 219 219 219], shape=(10,), dtype=int64)\n",
      "tf.Tensor([44 52 43 48 39 48 50 52 50 55], shape=(10,), dtype=int64)\n",
      "tf.Tensor([219 219 219 219 219 219 219 219 219 219], shape=(10,), dtype=int64)\n",
      "tf.Tensor([42 45 47 40 48 59 44 55 49 44], shape=(10,), dtype=int64)\n",
      "tf.Tensor([219 219 219 219 219 219 219 219 219 219], shape=(10,), dtype=int64)\n",
      "tf.Tensor([43 53 50 46 54 61 45 54 49 48], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "all_dgms = [[item[:10] for item in pds] \\\n",
    "        for pds in circle_pipeline.all_persistence_diagrams]\n",
    "all_dgms = [[stack_ragged([tf.convert_to_tensor(item) for item in pds]) for pds in dgms] for dgms in all_dgms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa48f595-9d91-4bc2-a02c-099e23114d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dgms = [[item[:10] for item in pds] \\\n",
    "        for pds in circle_pipeline.all_persistence_diagrams] # 4, hom_dims, num_sims, None, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ebca476-0e4d-4093-8998-42ecb6e228e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33e91d0f-d345-4825-b488-73601c1db798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, None, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(all_dgms[0], axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66274702-f7d0-4553-bacb-08470489906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [   ExtraDimLayer(PerslayLayer(perslays)),\n",
    "        ExtraDimLayer(tf.keras.layers.Conv2D(8, (3,3), padding='same', activation = \"relu\", input_shape=(res, res, 2))),\n",
    "        ExtraDimLayer(tf.keras.layers.MaxPooling2D((2, 2), strides = 2)),\n",
    "        ExtraDimLayer(tf.keras.layers.Flatten()),\n",
    "        tf.keras.layers.Dense(12, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(2)\n",
    "    ]\n",
    ")\n",
    "op = model(dgms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aef564-38e2-4cc5-a65a-6b902d2b2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39eea556-be6e-446d-9283-22b1e40f1885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, None, 2)\n",
      "(10, None, 2)\n"
     ]
    }
   ],
   "source": [
    "plays = PerslayLayer(perslays)\n",
    "vectors = plays(dgms[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef4615c3-56d6-4702-b0ad-e9a0dbdb168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 24, 24, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f0f1d-e007-47d7-aea0-821203a68bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PerslayIMNNLayer():\n",
    "    def __init__(self, perslay_comp, \n",
    "                 data_splits = [0.5, 0.25, 0.25], \\\n",
    "                 optimizer = tf.keras.optimizers.Adam(learning_rate= 1e-3), \\\n",
    "                 epochs = 100, batch_size = 512, verbose = 0, \\\n",
    "                 callbacks = None, \\\n",
    "                 name = \"Compression Layer\"):\n",
    "        \"\"\"\n",
    "        Initialize an IMNNLayer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        comp : tf.keras.Model\n",
    "            Compression model to extract information from the persistent \n",
    "            summaries.\n",
    "        data_splits : list, optional\n",
    "            Data split percentages for training, validation, and testing.\n",
    "            The default is [0.5, 0.25, 0.25].\n",
    "        optimizer : tf.keras.optimizers.Optimizer, optional\n",
    "            Optimizer for training. The default is Adam with learning rate 1e-3.\n",
    "        epochs : int, optional\n",
    "            Number of training epochs. The default is 100.\n",
    "        batch_size : int, optional\n",
    "            Batch size for training. The default is 512.\n",
    "        verbose : int, optional\n",
    "            Verbosity level for training. The default is 0.\n",
    "        callbacks : list, optional\n",
    "            List of callbacks for training. The default is None.\n",
    "        name : str, optional\n",
    "            Name for the IMNNLayer. The default is \"Compression Layer\".\n",
    "        \"\"\"\n",
    "        self.perslay_comp = perslay_comp\n",
    "        self.comp = comp\n",
    "        self.data_splits = data_splits\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.callbacks = callbacks\n",
    "        self.is_trained = False\n",
    "        super().__init__(name)\n",
    "    \n",
    "    def split_data(self, all_pds):\n",
    "        \"\"\"\n",
    "        Split input vectors into training, validation, and test sets.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        all_pds : tf.Tensor\n",
    "            Input vectors.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        train_vecs : tf.Tensor\n",
    "            Training vectors.\n",
    "        valid_vecs : tf.Tensor\n",
    "            Validation vectors.\n",
    "        test_vecs : tf.Tensor\n",
    "            Test vectors.\n",
    "        \"\"\"\n",
    "        # Transposing the first and the second index\n",
    "        # Old first index - indexing covariance and derivative simulations.\n",
    "        # Old second index - indexing simulation number.\n",
    "        inp_vecs = tf.einsum(\"ij...->ji...\", tf.stack(all_pds))\n",
    "        div = (np.array(self.data_splits) * inp_vecs.shape[0]).astype(int)\n",
    "        div = np.cumsum(div)\n",
    "        train_vecs, valid_vecs, test_vecs = \\\n",
    "            inp_vecs[:div[0]], inp_vecs[div[0]:div[1]], inp_vecs[div[1]:div[2]]\n",
    "        return train_vecs, valid_vecs, test_vecs\n",
    "    \n",
    "    def train_imnn(self, train_vecs, valid_vecs, delta_theta):\n",
    "        \"\"\"\n",
    "        Train and validate the IMNN model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_vecs : tf.Tensor\n",
    "            Training vectors.\n",
    "        valid_vecs : tf.Tensor\n",
    "            Validation vectors.\n",
    "        delta_theta : tf.Tensor\n",
    "            The step sizes for Fisher Analysis.\n",
    "        \"\"\"\n",
    "        custom_loss = self.fisher_loss(delta_theta)\n",
    "        model = self.comp\n",
    "        model.compile(optimizer = self.optimizer, loss = custom_loss)\n",
    "        # Creating \"fake\" training data since this optimization is unsupervized.\n",
    "        train_y = tf.zeros(shape = (train_vecs.shape[0], 1))\n",
    "        validation_data = (valid_vecs, \\\n",
    "                           tf.zeros(shape = (valid_vecs.shape[0], 1)))\n",
    "        # Fitting the model\n",
    "        self.history = model.fit(train_vecs, train_y,\\\n",
    "                                 epochs = self.epochs, \\\n",
    "                                  batch_size = self.batch_size, \\\n",
    "                                     validation_data = validation_data, \\\n",
    "                                         verbose = self.verbose, \\\n",
    "                                             callbacks = self.callbacks)\n",
    "        self.is_trained = True\n",
    "    \n",
    "    def computeFisher(self, all_pds, delta_theta):\n",
    "        \"\"\"\n",
    "        Train and compute Fisher information using the trained IMNN model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        all_pds : tf.Tensor\n",
    "            Input vectors.\n",
    "        delta_theta : tf.Tensor\n",
    "           Step sizes for Fisher analysis.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Fisher.fisherFromVecs\n",
    "            Fisher information object.\n",
    "        \"\"\"\n",
    "        if(not self.is_trained) :\n",
    "            train_vecs, valid_vecs, test_vecs = self.split_data(all_pds)\n",
    "            self.train_imnn(train_vecs, valid_vecs, delta_theta)\n",
    "            # Transposing data so that it is compatible for the Fisher \n",
    "            # analysis. The input format is given by the fisherFromVecs() init\n",
    "            # function.\n",
    "            test_vecs = tf.einsum(\"ij...->ji...\", test_vecs)\n",
    "        else : test_vecs = all_pds\n",
    "        fisher = Fisher.fisherFromVecs(self.comp(test_vecs), delta_theta)\n",
    "        return fisher\n",
    "      \n",
    "    def fisher_loss(self, delta_theta):\n",
    "        \"\"\"\n",
    "        Defines the Fisher Information based loss function.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        delta_theta : tf.Tensor\n",
    "            The step sizes for Fisher analysis.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        loss_fn\n",
    "            The negative log determinant of the Fisher matrix.\n",
    "        \"\"\"\n",
    "        @tf.function\n",
    "        def loss_fn(y_true, y_pred):\n",
    "            # Transposing data so that it is compatible for the Fisher \n",
    "            # analysis. The input format is given by the fisherFromVecs() init\n",
    "            # function.\n",
    "            y_t = tf.einsum(\"ij...->ji...\", y_pred)\n",
    "            fish = Fisher.fisherFromVecs(y_t, delta_theta, clean_data = False) \n",
    "            loss = -fish.lnDetF\n",
    "            return loss\n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164d483-b1aa-4056-9291-feee61d0e377",
   "metadata": {},
   "source": [
    "### Stacking retaining the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "78db326c-6b06-4ec8-a962-7a10beb39997",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 100\n",
    "all_dgms = [[item[:num_sims] for item in pds] \\\n",
    "        for pds in circle_pipeline.all_persistence_diagrams] # 4, hom_dims, num_sims, None, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "aa1b4551-4e5c-4d3c-bcee-8ccdf3fb9c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 24, 24, 2)\n",
      "(100, 5, 24, 24, 8)\n",
      "(100, 5, 12, 12, 8)\n",
      "(100, 5, 1152)\n"
     ]
    }
   ],
   "source": [
    "def stack_ragged(tensors):\n",
    "    tensors = [tf.constant(item) for item in tensors]\n",
    "    values = tf.concat(tensors, axis = 0)\n",
    "    lens = tf.stack([tf.shape(t, out_type=tf.int64)[0] for t in tensors])\n",
    "    return tf.RaggedTensor.from_row_lengths(values, lens)\n",
    "\n",
    "def transpose(all_dgms):\n",
    "    dgms_transpose = [list(map(list, zip(*dgms))) for dgms in all_dgms]\n",
    "    return list(map(list, zip(*dgms_transpose)))\n",
    "    \n",
    "\n",
    "def list_to_ragged_tensor(input_dgms, num_theta, num_hom_dim):\n",
    "    all_pds = transpose(input_dgms)\n",
    "    all_pds_list = []\n",
    "    for pds in all_pds:\n",
    "        pds_list = []\n",
    "        for dgms in pds: # Iterating over hom_dim\n",
    "            ragged_dgm = stack_ragged(dgms)\n",
    "            all_pds_list.append(ragged_dgm)\n",
    "    stacked = tf.concat(all_pds_list, axis = 0)\n",
    "    t1 = tf.RaggedTensor.from_uniform_row_length(stacked, num_hom_dim)\n",
    "    t2 = tf.RaggedTensor.from_uniform_row_length(t1, num_theta)\n",
    "    return t2\n",
    "t2 = list_to_ragged_tensor(all_dgms, 5, 2)\n",
    "model = tf.keras.Sequential(\n",
    "    [   ExtraDimLayer(PerslayLayer(perslays)),\n",
    "        ExtraDimLayer(tf.keras.layers.Conv2D(8, (3,3), padding='same', activation = \"relu\", input_shape=(res, res, 2))),\n",
    "        ExtraDimLayer(tf.keras.layers.MaxPooling2D((2, 2), strides = 2)),\n",
    "        ExtraDimLayer(tf.keras.layers.Flatten()),\n",
    "        tf.keras.layers.Dense(12, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(2)\n",
    "    ]\n",
    ")\n",
    "# op = model(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4e8b2d7b-8de2-419e-ac8b-5c1800e2a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 t2 = list_to_ragged_tensor(all_dgms, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5b76e637-985d-45bb-bbf3-ef2b8e432d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, 24, 24, 2)\n",
      "60 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [   ExtraDimLayer(PerslayLayer(perslays))\n",
    "    ]\n",
    ")\n",
    "\n",
    "%timeit -n 1 -r 1 op = model(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e1883c9c-5706-437d-bd2f-4f0be15257d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.random.randint(num_sims); hom_dim = np.random.randint(2); sim_idx = np.random.randint(5);\n",
    "diff = t2[ind][sim_idx][hom_dim] - all_dgms[sim_idx][hom_dim][ind]\n",
    "np.max(diff), np.min(diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnvbkup",
   "language": "python",
   "name": "newenvbkup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
